{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary:\n",
      "['don' 'great' 'is' 'like' 'love' 'movie' 'terrible' 'this']\n",
      "\n",
      "Bag-of-Words Matrix:\n",
      "[[0 0 0 0 1 1 0 1]\n",
      " [0 1 1 0 0 1 0 1]\n",
      " [1 0 0 1 0 1 0 1]\n",
      " [0 0 1 0 0 1 1 1]]\n"
     ]
    }
   ],
   "source": [
    "#Feature extraction with bag of words\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Sample input documents\n",
    "documents = [\n",
    "    \"I love this movie\",\n",
    "    \"This movie is great\",\n",
    "    \"I don't like this movie\",\n",
    "    \"This movie is terrible\"\n",
    "]\n",
    "\n",
    "# Step 1: Create an instance of the CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "# Step 2: Fit the vectorizer on the documents and transform the documents into a bag-of-words matrix\n",
    "X = vectorizer.fit_transform(documents)\n",
    "\n",
    "# Step 3: Print the feature names (words in the vocabulary)\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "print(\"Vocabulary:\")\n",
    "print(feature_names)\n",
    "\n",
    "# Step 4: Print the bag-of-words matrix\n",
    "print(\"\\nBag-of-Words Matrix:\")\n",
    "print(X.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary:\n",
      "['don' 'great' 'is' 'like' 'love' 'movie' 'terrible' 'this']\n",
      "\n",
      "TF-IDF Matrix:\n",
      "[[0.         0.         0.         0.         0.8046125  0.41988018\n",
      "  0.         0.41988018]\n",
      " [0.         0.67943473 0.53567415 0.         0.         0.35455723\n",
      "  0.         0.35455723]\n",
      " [0.62688384 0.         0.         0.62688384 0.         0.32713399\n",
      "  0.         0.32713399]\n",
      " [0.         0.         0.53567415 0.         0.         0.35455723\n",
      "  0.67943473 0.35455723]]\n"
     ]
    }
   ],
   "source": [
    "# feature extraction with TF_IDF\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Sample input documents\n",
    "documents = [\n",
    "    \"I love this movie\",\n",
    "    \"This movie is great\",\n",
    "    \"I don't like this movie\",\n",
    "    \"This movie is terrible\"\n",
    "]\n",
    "\n",
    "# Step 1: Create an instance of the TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Step 2: Fit the vectorizer on the documents and transform the documents into a TF-IDF matrix\n",
    "X = vectorizer.fit_transform(documents)\n",
    "\n",
    "# Step 3: Print the feature names (words in the vocabulary)\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "print(\"Vocabulary:\")\n",
    "print(feature_names)\n",
    "\n",
    "# Step 4: Print the TF-IDF matrix\n",
    "print(\"\\nTF-IDF Matrix:\")\n",
    "print(X.toarray())\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual class ['positive']\n",
      "Predicted class ['negative']\n",
      "Accuracy: 0.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# Sample input documents and corresponding labels\n",
    "documents = [\n",
    "    \"I love this movie\",\n",
    "    \"This movie is great\",\n",
    "    \"I don't like this movie\",\n",
    "    \"This movie is terrible\"\n",
    "]\n",
    "\n",
    "labels = [\"positive\", \"positive\", \"negative\", \"negative\"]\n",
    "\n",
    "# Step 1: Split the dataset into a training set and a validation set\n",
    "X_train, X_val, y_train, y_val = train_test_split(documents, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 2: Create an instance of the CountVectorizer and fit it on the training data\n",
    "vectorizer = CountVectorizer()\n",
    "X_train_transformed = vectorizer.fit_transform(X_train)\n",
    "\n",
    "# Step 3: Train the Naive Bayes classifier\n",
    "classifier = MultinomialNB()\n",
    "classifier.fit(X_train_transformed, y_train)\n",
    "\n",
    "# Step 4: Transform the validation data using the fitted vectorizer\n",
    "X_val_transformed = vectorizer.transform(X_val)\n",
    "\n",
    "# Step 5: Predict the sentiment labels for the validation data\n",
    "y_pred = classifier.predict(X_val_transformed)\n",
    "print(f\"Actual class {y_val}\")\n",
    "print(f\"Predicted class {y_pred}\")\n",
    "# Step 6: Evaluate the performance of the classifier\n",
    "accuracy = (y_pred == y_val).mean()\n",
    "print(\"Accuracy:\", accuracy)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted sentiment: ['positive']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# Sample input documents and corresponding labels\n",
    "documents = [\n",
    "    \"I love this movie\",\n",
    "    \"This movie is great\",\n",
    "    \"I don't like this movie\",\n",
    "    \"This movie is terrible\"\n",
    "]\n",
    "\n",
    "labels = [\"positive\", \"positive\", \"negative\", \"negative\"]\n",
    "\n",
    "# Step 1: Create an instance of the CountVectorizer and fit it on the documents\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(documents)\n",
    "\n",
    "# Step 2: Train the Naive Bayes classifier\n",
    "classifier = MultinomialNB()\n",
    "classifier.fit(X, labels)\n",
    "\n",
    "# Step 3: Predict the sentiment for a new document\n",
    "new_document = \"I love this great movie\"\n",
    "new_document_transformed = vectorizer.transform([new_document])\n",
    "predicted_sentiment = classifier.predict(new_document_transformed)\n",
    "\n",
    "print(\"Predicted sentiment:\", predicted_sentiment)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability of negative: 0.1618606703349758\n",
      "Probability of positive: 0.8381393296650242\n"
     ]
    }
   ],
   "source": [
    "#calculating probabilities\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# Sample input documents and corresponding labels\n",
    "documents = [\n",
    "    \"I love this movie\",\n",
    "    \"This movie is great\",\n",
    "    \"I don't like this movie\",\n",
    "    \"This movie is terrible\"\n",
    "]\n",
    "\n",
    "labels = [\"positive\", \"positive\", \"negative\", \"negative\"]\n",
    "\n",
    "# Step 1: Create an instance of the CountVectorizer and fit it on the documents\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(documents)\n",
    "\n",
    "# Step 2: Train the Naive Bayes classifier\n",
    "classifier = MultinomialNB()\n",
    "classifier.fit(X, labels)\n",
    "\n",
    "# Step 3: Calculate the probabilities for a new document\n",
    "new_document = \"I love this great movie\"\n",
    "new_document_transformed = vectorizer.transform([new_document])\n",
    "\n",
    "# Step 4: Calculate the probability of each sentiment category\n",
    "probabilities = classifier.predict_proba(new_document_transformed)\n",
    "\n",
    "# Step 5: Print the probabilities\n",
    "sentiment_categories = classifier.classes_\n",
    "for category, probability in zip(sentiment_categories, probabilities[0]):\n",
    "    print(f\"Probability of {category}: {probability}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.0\n",
      "Precision: 0.0\n",
      "Recall: 0.0\n",
      "F1-score: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\dell\\pycharmprojects\\nlp\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\users\\dell\\pycharmprojects\\nlp\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'y' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[31], line 51\u001B[0m\n\u001B[0;32m     48\u001B[0m classifier \u001B[38;5;241m=\u001B[39m MultinomialNB()\n\u001B[0;32m     50\u001B[0m \u001B[38;5;66;03m# Perform cross-validation and calculate accuracy scores\u001B[39;00m\n\u001B[1;32m---> 51\u001B[0m cv_scores \u001B[38;5;241m=\u001B[39m cross_val_score(classifier, X, \u001B[43my\u001B[49m , cv\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m5\u001B[39m)\n\u001B[0;32m     53\u001B[0m \u001B[38;5;66;03m# Print the average accuracy across cross-validation folds\u001B[39;00m\n\u001B[0;32m     54\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAverage Accuracy:\u001B[39m\u001B[38;5;124m\"\u001B[39m, cv_scores\u001B[38;5;241m.\u001B[39mmean())\n",
      "\u001B[1;31mNameError\u001B[0m: name 'y' is not defined"
     ]
    }
   ],
   "source": [
    "#Evaluation\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Assuming y_val contains the true labels and y_pred contains the predicted labels\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_val, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Calculate precision\n",
    "precision = precision_score(y_val, y_pred, average='macro')\n",
    "print(\"Precision:\", precision)\n",
    "\n",
    "# Calculate recall\n",
    "recall = recall_score(y_val, y_pred, average='macro')\n",
    "print(\"Recall:\", recall)\n",
    "\n",
    "# Calculate F1-score\n",
    "f1 = f1_score(y_val, y_pred, average='macro')\n",
    "print(\"F1-score:\", f1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Assuming X contains the feature matrix and y contains the labels\n",
    "\n",
    "# Create an instance of the classifier\n",
    "classifier = MultinomialNB()\n",
    "\n",
    "# Perform cross-validation and calculate accuracy scores\n",
    "cv_scores = cross_val_score(classifier, X, y , cv=5)\n",
    "\n",
    "# Print the average accuracy across cross-validation folds\n",
    "print(\"Average Accuracy:\", cv_scores.mean())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p-value 0.52 and alpha value 0.05\n",
      "The difference in performance is not statistically significant.\n"
     ]
    }
   ],
   "source": [
    "#Statistical significance Testing (Non parametric test)\n",
    "import numpy as np\n",
    "from sklearn.utils import resample\n",
    "\n",
    "# Evaluation metrics of Classifier A and Classifier B\n",
    "metric_classifier_a = [0.82, 0.86, 0.88, 0.84, 0.86]\n",
    "metric_classifier_b = [0.78, 0.84, 0.83, 0.87, 0.85]\n",
    "\n",
    "# Calculate the observed difference in performance\n",
    "observed_difference = np.mean(metric_classifier_a) - np.mean(metric_classifier_b)\n",
    "\n",
    "# Set the number of bootstrap iterations\n",
    "n_iterations = 1000\n",
    "\n",
    "# Perform the paired bootstrap test\n",
    "differences = np.subtract(metric_classifier_a, metric_classifier_b)\n",
    "bootstrap_differences = []\n",
    "for _ in range(n_iterations):\n",
    "    resampled_a = resample(metric_classifier_a)\n",
    "    resampled_b = resample(metric_classifier_b)\n",
    "    resampled_difference = np.mean(resampled_a) - np.mean(resampled_b)\n",
    "    bootstrap_differences.append(resampled_difference)\n",
    "\n",
    "# Calculate the p-value\n",
    "p_value = (np.abs(bootstrap_differences) >= np.abs(observed_difference)).mean()\n",
    "\n",
    "# Determine statistical significance\n",
    "alpha = 0.05  # Significance level\n",
    "\n",
    "print(f\"p-value {p_value} and alpha value {alpha}\")\n",
    "if p_value < alpha:\n",
    "    print(\"The difference in performance is statistically significant.\")\n",
    "else:\n",
    "    print(\"The difference in performance is not statistically significant.\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}