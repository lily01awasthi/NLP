{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary:\n",
      "['don' 'great' 'is' 'like' 'love' 'movie' 'terrible' 'this']\n",
      "\n",
      "Bag-of-Words Matrix:\n",
      "[[0 0 0 0 1 1 0 1]\n",
      " [0 1 1 0 0 1 0 1]\n",
      " [1 0 0 1 0 1 0 1]\n",
      " [0 0 1 0 0 1 1 1]]\n"
     ]
    }
   ],
   "source": [
    "#Feature extraction with bag of words\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Sample input documents\n",
    "documents = [\n",
    "    \"I love this movie\",\n",
    "    \"This movie is great\",\n",
    "    \"I don't like this movie\",\n",
    "    \"This movie is terrible\"\n",
    "]\n",
    "\n",
    "# Step 1: Create an instance of the CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "# Step 2: Fit the vectorizer on the documents and transform the documents into a bag-of-words matrix\n",
    "X = vectorizer.fit_transform(documents)\n",
    "\n",
    "# Step 3: Print the feature names (words in the vocabulary)\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "print(\"Vocabulary:\")\n",
    "print(feature_names)\n",
    "\n",
    "# Step 4: Print the bag-of-words matrix\n",
    "print(\"\\nBag-of-Words Matrix:\")\n",
    "print(X.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary:\n",
      "['don' 'great' 'is' 'like' 'love' 'movie' 'terrible' 'this']\n",
      "\n",
      "TF-IDF Matrix:\n",
      "[[0.         0.         0.         0.         0.8046125  0.41988018\n",
      "  0.         0.41988018]\n",
      " [0.         0.67943473 0.53567415 0.         0.         0.35455723\n",
      "  0.         0.35455723]\n",
      " [0.62688384 0.         0.         0.62688384 0.         0.32713399\n",
      "  0.         0.32713399]\n",
      " [0.         0.         0.53567415 0.         0.         0.35455723\n",
      "  0.67943473 0.35455723]]\n"
     ]
    }
   ],
   "source": [
    "# feature extraction with TF_IDF\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Sample input documents\n",
    "documents = [\n",
    "    \"I love this movie\",\n",
    "    \"This movie is great\",\n",
    "    \"I don't like this movie\",\n",
    "    \"This movie is terrible\"\n",
    "]\n",
    "\n",
    "# Step 1: Create an instance of the TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Step 2: Fit the vectorizer on the documents and transform the documents into a TF-IDF matrix\n",
    "X = vectorizer.fit_transform(documents)\n",
    "\n",
    "# Step 3: Print the feature names (words in the vocabulary)\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "print(\"Vocabulary:\")\n",
    "print(feature_names)\n",
    "\n",
    "# Step 4: Print the TF-IDF matrix\n",
    "print(\"\\nTF-IDF Matrix:\")\n",
    "print(X.toarray())\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual class ['positive']\n",
      "Predicted class ['negative']\n",
      "Accuracy: 0.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# Sample input documents and corresponding labels\n",
    "documents = [\n",
    "    \"I love this movie\",\n",
    "    \"This movie is great\",\n",
    "    \"I don't like this movie\",\n",
    "    \"This movie is terrible\"\n",
    "]\n",
    "\n",
    "labels = [\"positive\", \"positive\", \"negative\", \"negative\"]\n",
    "\n",
    "# Step 1: Split the dataset into a training set and a validation set\n",
    "X_train, X_val, y_train, y_val = train_test_split(documents, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 2: Create an instance of the CountVectorizer and fit it on the training data\n",
    "vectorizer = CountVectorizer()\n",
    "X_train_transformed = vectorizer.fit_transform(X_train)\n",
    "\n",
    "# Step 3: Train the Naive Bayes classifier\n",
    "classifier = MultinomialNB()\n",
    "classifier.fit(X_train_transformed, y_train)\n",
    "\n",
    "# Step 4: Transform the validation data using the fitted vectorizer\n",
    "X_val_transformed = vectorizer.transform(X_val)\n",
    "\n",
    "# Step 5: Predict the sentiment labels for the validation data\n",
    "y_pred = classifier.predict(X_val_transformed)\n",
    "print(f\"Actual class {y_val}\")\n",
    "print(f\"Predicted class {y_pred}\")\n",
    "# Step 6: Evaluate the performance of the classifier\n",
    "accuracy = (y_pred == y_val).mean()\n",
    "print(\"Accuracy:\", accuracy)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted sentiment: ['positive']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# Sample input documents and corresponding labels\n",
    "documents = [\n",
    "    \"I love this movie\",\n",
    "    \"This movie is great\",\n",
    "    \"I don't like this movie\",\n",
    "    \"This movie is terrible\"\n",
    "]\n",
    "\n",
    "labels = [\"positive\", \"positive\", \"negative\", \"negative\"]\n",
    "\n",
    "# Step 1: Create an instance of the CountVectorizer and fit it on the documents\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(documents)\n",
    "\n",
    "# Step 2: Train the Naive Bayes classifier\n",
    "classifier = MultinomialNB()\n",
    "classifier.fit(X, labels)\n",
    "\n",
    "# Step 3: Predict the sentiment for a new document\n",
    "new_document = \"I love this great movie\"\n",
    "new_document_transformed = vectorizer.transform([new_document])\n",
    "predicted_sentiment = classifier.predict(new_document_transformed)\n",
    "\n",
    "print(\"Predicted sentiment:\", predicted_sentiment)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability of negative: 0.1618606703349758\n",
      "Probability of positive: 0.8381393296650242\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# Sample input documents and corresponding labels\n",
    "documents = [\n",
    "    \"I love this movie\",\n",
    "    \"This movie is great\",\n",
    "    \"I don't like this movie\",\n",
    "    \"This movie is terrible\"\n",
    "]\n",
    "\n",
    "labels = [\"positive\", \"positive\", \"negative\", \"negative\"]\n",
    "\n",
    "# Step 1: Create an instance of the CountVectorizer and fit it on the documents\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(documents)\n",
    "\n",
    "# Step 2: Train the Naive Bayes classifier\n",
    "classifier = MultinomialNB()\n",
    "classifier.fit(X, labels)\n",
    "\n",
    "# Step 3: Calculate the probabilities for a new document\n",
    "new_document = \"I love this great movie\"\n",
    "new_document_transformed = vectorizer.transform([new_document])\n",
    "\n",
    "# Step 4: Calculate the probability of each sentiment category\n",
    "probabilities = classifier.predict_proba(new_document_transformed)\n",
    "\n",
    "# Step 5: Print the probabilities\n",
    "sentiment_categories = classifier.classes_\n",
    "for category, probability in zip(sentiment_categories, probabilities[0]):\n",
    "    print(f\"Probability of {category}: {probability}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}