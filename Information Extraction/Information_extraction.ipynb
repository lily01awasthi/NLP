{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Named Entities Extracted are: [('June 15, 2023', 'DATE'), ('October 5th to October 8th, 2022', 'DATE'), ('September 30, 2022', 'DATE'), ('Yesterday', 'DATE'), ('June 11, 2023', 'DATE'), ('Next week', 'DATE'), ('Friday, June 16th, 2023', 'DATE')]\n",
      "Relations Extracted are : [('I', 'have'), ('conference', 'take'), ('we', 'plan')]\n",
      "Dates Extracted are : ['June 12, 2023', 'June 15, 2023', 'June 12, 2023', 'October 12, 2023', 'June 05, 2023', 'October 12, 2023', 'June 08, 2023', 'June 12, 2022', 'September 12, 2023', 'June 30, 2023', 'June 12, 2022', 'June 12, 2023', 'June 11, 2023', 'June 12, 2023', 'June 16, 2023', 'June 12, 2023', 'June 16, 2023', 'June 12, 2023']\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "import spacy\n",
    "from dateutil import parser\n",
    "\n",
    "text = \"I have a meeting scheduled on June 15, 2023. \" \\\n",
    "       \"The conference will take place from October 5th to October 8th\" \\\n",
    "       \", 2022. Our project deadline is set for September 30, 2022. \" \\\n",
    "       \"Yesterday's date was June 11, 2023. Next week, \" \\\n",
    "       \"we plan to have a team gathering on Friday, June 16th, 2023.\"\n",
    "\n",
    "# Tokenize text into sentences\n",
    "sentences = sent_tokenize(text)\n",
    "\n",
    "# Tokenize sentences into words\n",
    "words = [word_tokenize(sentence) for sentence in sentences]\n",
    "\n",
    "# Remove stopwords\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "filtered_words = [[word for word in sentence if word.lower() not in stopwords] for sentence in words]\n",
    "\n",
    "# Load spaCy model and process text\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(text)\n",
    "\n",
    "# Extract named entities\n",
    "entities = [(entity.text, entity.label_) for entity in doc.ents]\n",
    "print(f\"Named Entities Extracted are: {entities}\")\n",
    "\n",
    "relations = []\n",
    "for token in doc:\n",
    "    if token.dep_ == \"nsubj\" and token.head.pos_ == \"VERB\":\n",
    "        subject = token.text\n",
    "        verb = token.head.text\n",
    "        relation = (subject, verb)\n",
    "        relations.append(relation)\n",
    "print(f\"Relations Extracted are : {relations}\")\n",
    "\n",
    "dates = []\n",
    "for word in text.split():\n",
    "    try:\n",
    "        date = parser.parse(word, fuzzy=True)\n",
    "        dates.append(date.strftime(\"%B %d, %Y\"))\n",
    "    except ValueError:\n",
    "        pass\n",
    "\n",
    "print(f\"Dates Extracted are : {dates}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}